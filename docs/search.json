[
  {
    "objectID": "about.html#eddy-covariance",
    "href": "about.html#eddy-covariance",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Eddy Covariance",
    "text": "Eddy Covariance\n\n\nSemi-continuous, ecosystem-scale measurements of energy, water, and trace gas fluxes.\n\nNoisy, voluminous data sets\n\nFrequent gaps\nObservational bias\n\nWell suited for machine learning!\n\n\n\n\nBurns Bog EC StationDelta, BC"
  },
  {
    "objectID": "about.html#neural-networks",
    "href": "about.html#neural-networks",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Neural Networks",
    "text": "Neural Networks\nUniversal approximators: can map any continuous function to an arbitrary degree accuracy.\n\nWith enough hidden nodes, will fit any pattern in a dataset\n\nCare must be taken to ensure the patterns are real\nEarly stopping allows\n\nWell suited for non-linear, multi-variate response functions\n\nCapable interpolation and extrapolation"
  },
  {
    "objectID": "about.html#commonly-cited-limitations",
    "href": "about.html#commonly-cited-limitations",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Commonly Cited Limitations",
    "text": "Commonly Cited Limitations\n\n\n\n\n\n\n\n\n\nIssue\nSolutions\n\n\n\n\nOver-fitting\n- Model ensembles- 3-way cross validation - Pruning inputs\n\n\nBlack boxes models\n- Plot partial derivatives - Feature importance\n\n\nComputationally expensive\n- Tensorflow - GPU processing"
  },
  {
    "objectID": "about.html#example-data",
    "href": "about.html#example-data",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Example Data",
    "text": "Example Data\n\n\nBurns Bog EC station\n\nHarvested peatland undergoing active restoration\n8+ years of meteorological & flux (CO2 and CH4) data"
  },
  {
    "objectID": "about.html#training-procedures",
    "href": "about.html#training-procedures",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Training Procedures",
    "text": "Training Procedures\n\n\n\nLarger ensemble = more robust model\n\nN <= 10 for data exploration/pruning\n\nThree way cross-validation\n\nTrain/validate/test\n\nEarly Stopping: after e epochs\n\ne = 2 for pruning stage"
  },
  {
    "objectID": "about.html#pruning-inputs",
    "href": "about.html#pruning-inputs",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Pruning Inputs",
    "text": "Pruning Inputs\nCalculate partial first derivative of the output with respect to each input over test data domain.\n\nRelative Influence (RI) of inputs\n\nNormalized sum of squared derivatives (SSD)\n\nIteratively remove inputs with RI below a threshold\n\nUse set of random scalars inputs to determine threshold\n\ne.g., a float [0-1], a skewed float [0-1].25, and a binary integer (0/1)"
  },
  {
    "objectID": "about.html#before-and-after-pruning-fco2",
    "href": "about.html#before-and-after-pruning-fco2",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Before and After Pruning FCO2",
    "text": "Before and After Pruning FCO2"
  },
  {
    "objectID": "about.html#the-final-model",
    "href": "about.html#the-final-model",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "The Final Model",
    "text": "The Final Model\nOnce pruning is complete, re-train the final production level model, excluding the random scalars\n\nIncrease the ensemble size (e.g., N =30)\n\nCould increase early stopping criteria (e.g., e = 10)\nLarger e drastically increases training\n\nPlot the model derivatives as a final check\n\nIf derivatives look implausible\n\nAdjust inputs/parameters and try again"
  },
  {
    "objectID": "about.html#plotting-derivatives",
    "href": "about.html#plotting-derivatives",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Plotting Derivatives",
    "text": "Plotting Derivatives\nHelps ensure model responses are physically plausible\n\nAn essential step and key advantage of NN models\nRaw derivatives show true feature responses\nNormalized derivatives scaled by input variance\n\nRelative input effects on common scale\nWhat the model “sees”\n\n95% confidence intervals around derivatives indicate modeled confidence in relationships"
  },
  {
    "objectID": "about.html#partial-derivatives-of-fco2",
    "href": "about.html#partial-derivatives-of-fco2",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Partial Derivatives of FCO2",
    "text": "Partial Derivatives of FCO2"
  },
  {
    "objectID": "about.html#normalized-derivatives-of-fco2",
    "href": "about.html#normalized-derivatives-of-fco2",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Normalized Derivatives of FCO2",
    "text": "Normalized Derivatives of FCO2"
  },
  {
    "objectID": "about.html#model-performance-fco2",
    "href": "about.html#model-performance-fco2",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Model Performance FCO2",
    "text": "Model Performance FCO2\n\n\nPlot the model outputs and validation metrics calculated with the test data.\n\n\n\n\n\n\n\n\n\n\n\nMetric\nScore\n\n\n\n\nRMSE\n0.45 \\(\\mu mol\\) \\(m^{-2}s^{-1}\\)\n\n\nr2\n0.89"
  },
  {
    "objectID": "about.html#before-and-after-pruning-fch4",
    "href": "about.html#before-and-after-pruning-fch4",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Before and After Pruning FCH4",
    "text": "Before and After Pruning FCH4"
  },
  {
    "objectID": "about.html#normalized-derivatives-of-fch4",
    "href": "about.html#normalized-derivatives-of-fch4",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Normalized Derivatives of FCH4",
    "text": "Normalized Derivatives of FCH4"
  },
  {
    "objectID": "about.html#model-performance-fch4",
    "href": "about.html#model-performance-fch4",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Model Performance FCH4",
    "text": "Model Performance FCH4\n\n\nPlot the model outputs and validation metrics calculated with the test data.\n\n\n\n\n\n\n\n\n\n\n\nMetric\nScore\n\n\n\n\nRMSE\n8.58 $\n\n\n\nmol$ \\(m^{-2}s^{-1}\\)\n\n\nr2\n0.63"
  },
  {
    "objectID": "about.html#next-steps",
    "href": "about.html#next-steps",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "Next Steps",
    "text": "Next Steps\n\nCustom NN architecture: Separating input layers may allow us partition fluxes.\n\ne.g., FCO2 into GPP and ER\n\nFlux footprints: map response to spatial heterogenity\nUpscaling: in space and time\nu* filtering: partial derivatives could identify u* thresholds\nCompare to process based models (e.g., CLASSIC)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A Framework for Applying Neural Networks to Eddy Covariance Data",
    "section": "",
    "text": "Abstract\nEddy covariance (EC) is a passive, non-invasive method for measuring ecosystem-atmosphere trace gas exchange. It has become increasingly popular in recent years as hardware and software have become more accessible. Eddy covariance cannot measure fluxes continuously because the assumptions underpinning the method are not valid under all meteorologic conditions, but data from EC sites are widely used to monitor ecosystem scale energy, water, and carbon exchange. Trace gas fluxes tend to exhibit spatially and temporally variable, non-linear dependence upon numerous drivers. Multi-year EC data sets have hundreds of thousands of data points and flux time series contain both noise and data gaps. These factors make EC data poorly suited for analysis with traditional statistical methods. Here we present a guidance for leveraging the flexibility and functionality of Neural network (NN) models for working with EC data. Neural networks are a flexible machine learning method and an ideal tool for working with large multivariate datasets with complex non-linear dependencies. They offer control over the structure a model and inspection of model derivatives provides a method for ensuring that relationships mapped by a NN are physically plausible. We demonstrate methods for inferential modelling with NN and EC data, provide examples demonstrating how model derivatives can be used to detect and visualize the functional relationships, and offer comparisons to other common ML methods."
  },
  {
    "objectID": "NN_for_EC.html",
    "href": "NN_for_EC.html",
    "title": "Neural Networks for Eddy Covariance",
    "section": "",
    "text": "## Import some standard packages and define a few functions\nimport os\n# Hide default info, logs, and warnings - comment out if you need to troubleshoot\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nimport time\nimport shutil\nimport importlib\nimport numpy as np\nimport pandas as pd\n# from matplotlib import cm\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom Scripts import PlotHelpers\n# from matplotlib.colors import Normalize\nfrom Scripts import ReadDB, MiscFuncs, NNetFuncs\n\ndbNames = {\n    'Clean/SecondStage/TA_1_1_1':'T air',\n    'Clean/SecondStage/RH_1_1_1':'RH',\n    'Clean/SecondStage/FC':'FCO2',\n    'Clean/SecondStage/FCH4':'FCH4',\n    'Clean/SecondStage/PPFD_IN_1_1_1':'PPFD',\n    'Clean/SecondStage/NETRAD_1_1_1':'Rn',\n    'Clean/SecondStage/P_1_1_1':'Precip',\n    'Flux/qc_co2_flux':'qc_FCO2',\n    'Flux/qc_ch4_flux':'qc_FCH4',\n    'Clean/SecondStage/USTAR':'u*',\n    'Clean/SecondStage/TS_1':'T soil 5cm',\n    'Clean/SecondStage/TS_2':'T soil 10cm',\n    'Clean/SecondStage/TS_3':'T soil 50cm',\n    'Clean/SecondStage/wind_speed':'Wind speed',\n    'Clean/SecondStage/wind_dir':'Wind dir',\n    'Clean/SecondStage/WTD_1_1_1':'Water table',\n}\n\nLocal = '/mnt/c/Users/User/PostDoc_Work/database/'\nRemote = '/mnt/w/'\n\nDir = Local\n\nSite = 'BB'\n\nread_new = True\nif read_new == True:\n    Data = ReadDB.get_Traces(Site,list(dbNames.keys()),Dir=Dir)\n    Data = Data.rename(columns=dbNames)\n    Data.to_csv(f'InputData/{Site}_Data.csv')\n\nelse:\n    Data = pd.read_csv(f'InputData/{Site}_Data.csv',parse_dates=['TimeStamp'],index_col='TimeStamp')\n\n\n\n\n\nimportlib.reload(ReadDB)\n\nData['VPD'] = MiscFuncs.Calc_VPD(Data['T air'],Data['RH'])\nData['Water table'] = -1*(70-Data['Water table'])\nData['DOY'] = Data.index.dayofyear\n\ntarget = ['FCO2','FCH4']\n\nData['Rand']=np.random.random(Data['FCO2'].values.shape)\nData['Rand_Binary'] = Data['Rand']-.5\nData['Rand_Skew'] = Data['Rand']**.25\nData.loc[Data['Rand_Binary']>0,'Rand_Binary']=1\nData.loc[Data['Rand_Binary']<0,'Rand_Binary']=-1\nRand_Scalars=['Rand','Rand_Binary','Rand_Skew']\n\nprint(Data[['FCO2','FCH4']].describe())\nfilter = ReadDB.filterFlux(Data,target)\nfilter.QA_QC()\nfilter.dir_mask('Wind dir',[[0,45],[315,360]])\nfilter.rain('Precip',thresh=0)\nfilter.MAD(z=5)\nfilter.uStar('u*',u_thresh=0.1)\n\nData[['FCO2_Clean','FCH4_Clean']] = filter.df[['FCO2','FCH4']].copy()\n\nprint(Data[['FCO2_Clean','FCH4_Clean']].describe())\n\nexcludes = ['fco2','fch4','precip']\n\nFull_inputs = []\n\nfor val in list(Data.columns):\n    exct = 0\n    for ex in excludes:\n        if ex in val.lower():\n            exct += 1\n    if exct < 1:\n        Full_inputs.append(val)\n\nFull_inputs\n\n               FCO2          FCH4\ncount  33385.000000  37097.000000\nmean      -0.457040     51.854595\nstd        3.770148     68.253487\nmin      -45.689865   -198.555832\n25%       -1.767280      9.356360\n50%       -0.121570     33.294426\n75%        0.718945     89.551025\nmax       49.698837    695.056885\n         FCO2_Clean    FCH4_Clean\ncount  10940.000000  10248.000000\nmean      -0.525573     17.851301\nstd        1.363216     14.280396\nmin       -2.791655    -47.824982\n25%       -1.675785      7.303655\n50%       -0.608034     14.886700\n75%        0.466262     28.229795\nmax        2.990116     47.854935\n\n\n['T air',\n 'RH',\n 'PPFD',\n 'Rn',\n 'u*',\n 'T soil 5cm',\n 'T soil 10cm',\n 'T soil 50cm',\n 'Wind speed',\n 'Wind dir',\n 'Water table',\n 'VPD',\n 'DOY',\n 'Rand',\n 'Rand_Binary',\n 'Rand_Skew']"
  },
  {
    "objectID": "NN_for_EC.html#build-and-train-model",
    "href": "NN_for_EC.html#build-and-train-model",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Build and train model",
    "text": "Build and train model\n\nimportlib.reload(NNetFuncs)\n\n\ndef Build_Train_Eval(Run,print_sum=False):\n\n    config = Run['config']\n    Training = Run['Training']\n    \n    NNetFuncs.make_Dense_model(config,print_sum=print_sum)\n    Eval=NNetFuncs.train_model(config,Training)\n    _=NNetFuncs.run_Model(config,Eval)\n\nfor Run in Model_Runs.keys():\n    print(Run)\n    Build_Train_Eval(Model_Runs[Run],print_sum=True)\n    print('\\n\\n')\n\nFull_Model_FCH4\nModel: \"Full_Model_FCH4\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 16)]              0         \n                                                                 \n normalization (Normalizatio  (None, 16)               0         \n n)                                                              \n                                                                 \n dense (Dense)               (None, 160)               2720      \n                                                                 \n dense_1 (Dense)             (None, 1)                 161       \n                                                                 \n=================================================================\nTotal params: 2,881\nTrainable params: 2,881\nNon-trainable params: 0\n_________________________________________________________________\nNone\nTraining Time:\n 110.44  Seconds\nNN Model\n Validation metrics (ensemble mean): \nr2 =  0.67134 \nRMSE =  8.07566\nRun Time:\n 0.71  Seconds\n10 models\nMean epochs/model:  66.1\n\n\n\nFull_Model_FCO2\nModel: \"Full_Model_FCO2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 16)]              0         \n                                                                 \n normalization (Normalizatio  (None, 16)               0         \n n)                                                              \n                                                                 \n dense (Dense)               (None, 160)               2720      \n                                                                 \n dense_1 (Dense)             (None, 1)                 161       \n                                                                 \n=================================================================\nTotal params: 2,881\nTrainable params: 2,881\nNon-trainable params: 0\n_________________________________________________________________\nNone\nTraining Time:\n 49.99  Seconds\nNN Model\n Validation metrics (ensemble mean): \nr2 =  0.90287 \nRMSE =  0.42394\nRun Time:\n 0.78  Seconds\n10 models\nMean epochs/model:  27.5"
  },
  {
    "objectID": "about_BU.html",
    "href": "about_BU.html",
    "title": "Neural Networks for Eddy Covariance",
    "section": "",
    "text": "Ecosystem-scale fluxes of energy, water, and trace gases.\n\nSpatially integrated, semi-continuous\nNoisy, voluminous data\n\nIdeally suited for NN analysis!"
  },
  {
    "objectID": "about_BU.html#neural-networks",
    "href": "about_BU.html#neural-networks",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Neural Networks",
    "text": "Neural Networks\nPowerful machine learning algorithms that are well suited for non-linear, multi-variate response functions.\n\nUniversal approximators: can map any continuous function to an arbitrary degree of accuracy.\n\nGiven sufficient “hidden nodes”, will fit any pattern in a dataset\n\nCare must be taken to ensure the patterns are real\n\n\nCapable of interpolation and extrapolation"
  },
  {
    "objectID": "about_BU.html#commonly-cited-limitations",
    "href": "about_BU.html#commonly-cited-limitations",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Commonly Cited Limitations",
    "text": "Commonly Cited Limitations\n’Code” #| tbl-colwidths: [35,65] import pandas as pd\nfrom IPython.display import Markdown from tabulate import tabulate\ndf = pd.read_csv(‘About.csv’,sep=‘|’,index_col=‘Drawback’) Markdown(tabulate( df, headers=[“Limitation”, “Solutions”] ))\n\n# Objectives\n\nProvide a framework for applying NN models can be applied to EC data for both descriptive analysis and inferential modelling. \n \n* The [github repository](https://github.com/June-Skeeter/NN_Applications) linked to this presentation has Python code with functional examples that can be used to apply NN models.\n\n## Key Procedures\n\n* Early stopping: End training metrics (e.g., MSE) fail to improve for *e* training epochs\n    * *e* = 2 typically provides a robust, generalizable model\n\n* Ensembling: Train a set of N randomly initialled models on N unique interactions of training/testing data\n    * A small ensemble for ~10 models is sufficient in most applications\n\n* Input normalization: Z-norm scale all inputs to improve training\n\n## Key Procedures\n\n* Feature inspection: Calculating partial first (and second) derivatives of each input\n    * Sum of squared derivatives gives relative influence of each input over output\n    * Plotting model derivatives to help ensure mapped relationships are physically plausible\n        * An **essential step** and **key advantage** of NN models\n\n## A Simple Example\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\n\nThe Vapor Pressure Deficit (VPD):\n\n* Increases exponentially as a function of air temperature (Ta)\n* Decreases linearly as a function of relative humidity (RH).\n\n<!-- \n$$ ea_H = 0.61365*np.exp((17.502*Ta)/(240.97+Ta))$$\n$$e_H = RH*ea_H/100$$\n$$VPD = (ea_H - e_H)*10$$ -->\n\n\n:::\n::: {.column width=\"50%\"}\n\n\n'Code\"\n#| label: Estimating VPD\n#| fig-cap: \"VPD over a range of Ta, and RH values\"\n#| layout-ncol: 1\n#| warning: False\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom Scripts import MiscFuncs,PlotHelpers\nfrom Scripts import ReadDB, MiscFuncs, NNetFuncs\n\nunits = {\n    'TA':'$T_a^\\circ$C',\n    'RH':'RH %',\n    'VPD':'VPD hPa'\n    }\n\nlabels = {\n    'TA':'Air Temperature',\n    'RH':'Relative Humidity',\n    'VPD':'Vapor Pressure Deficit'\n    }\n\nrange_TA_RH,grid_TA,grid_RH,grid_VPD = MiscFuncs.Create_Grid(\n    np.linspace(-50,50),# Define a TA range (in C)\n    np.linspace(0,100), # Possible RH values\n    MiscFuncs.Calc_VPD # Return Vapor Pressure Defecit\n    )\n    \nbins = np.arange(-10,grid_VPD.max(),15)\ncmap = 'PuRd'\nnorm = [0,grid_VPD.max()]\n\nfig,ax=plt.subplots(1,figsize=(5,5))\nPlotHelpers.Contour_Plot(fig,ax,grid_TA,grid_RH,grid_VPD,cmap=cmap,norm=norm,unit = units['VPD'],bins=bins)\nax.set_xlabel('Air Temperature $^\\circ$C')\nax.set_ylabel('Relative Humidity %')\nax.set_title('Vapor Pressure Deficit (VPD)')\nplt.tight_layout()\n\n# # Use tensorfolow to calculate the first partial derivative of the function\n# X_tensor = tf.convert_to_tensor(range_TA_RH.T)\n# with tf.GradientTape(persistent=True) as tape:\n#     tape.watch(X_tensor)\n#     VPD_est = MiscFuncs.Calc_VPD(X_tensor) \n# # Get gradients of VPD_est with respect to X_tensor\n# Deriv = tape.gradient(VPD_est,X_tensor).numpy()\n\n# Derivatives = pd.DataFrame(\n#     data={\n#     'TA':range_TA_RH.T[:,0],\n#     'RH':range_TA_RH.T[:,1],\n#     'dVPD/dTA':Deriv[:,0],\n#     'dVPD/dRH':Deriv[:,1]\n#     }\n# )\n\n# fig,axes=plt.subplots(2,2,figsize=(8,8),sharey='row')\n\n# grid_dVPD_dTA = Deriv[:,0].T.reshape(grid_TA.shape)\n# grid_dVPD_dRH = Deriv[:,1].T.reshape(grid_RH.shape)\n\n# d_bins = np.arange(\n#     np.floor(Deriv).min(),np.ceil(Deriv).max(),.5\n#     )\n# d_cmap = 'bwr'\n# d_norm = [\n#     Deriv.min(),0, Deriv.max()\n#     ]\n    \n# ax,_ = PlotHelpers.Contour_Plot(fig,axes[0,0],grid_TA,grid_RH,grid_dVPD_dTA,cmap = d_cmap,norm=d_norm,bins=d_bins)\n# ax.set_title('dVPD dTa')\n\n# ax,_ = PlotHelpers.Contour_Plot(fig,axes[0,1],grid_TA,grid_RH,grid_dVPD_dRH,cmap = d_cmap,norm=d_norm,bins=d_bins)\n# ax.set_title('dVPD dRH')\n\n\n# y=['dVPD/dTA']\n# df = MiscFuncs.byInterval(Derivatives,'TA',y,bins=100)\n# ax = PlotHelpers.CI_Plot(axes[1,0],df,y[0])\n# # ax.set_title('Partial First Derivative\\nVPD with respect to Ta')\n\n# y=['dVPD/dRH']\n# df = MiscFuncs.byInterval(Derivatives,'RH',y,bins=100)\n# ax = PlotHelpers.CI_Plot(axes[1,1],df,y[0])\n# # ax.set_title('Partial First Derivative\\nVPD with respect to RH')\n\n\n# plt.tight_layout()\n\n:::\n::::"
  },
  {
    "objectID": "about_BU.html#partial-derivatives",
    "href": "about_BU.html#partial-derivatives",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\n’Code” #| label: Derivatives of VPD #| fig-cap: “This plot shows the partial first derivatives of VPD” #| layout-ncol: 1 #| warning: False grid_VPD.min()\n\n\n## Example Data\n\nBB1 Flux tower was established in 2015.\n\n'Code\"\nfrom Scripts import ReadDB\n\n# dbNames = {\n#     'TA_1_1_1':'TA',\n#     'RH_1_1_1':'RH'\n# }\n\n# read_new = False\n# if read_new == False:\n#     Data = ReadDB.get_Traces('BB',['TA_1_1_1','RH_1_1_1'],Dir='/mnt/c/Users/User/PostDoc_Work/database/')\n#     print(Data)\n#     Data = Data.dropna(axis=0)\n#     Data = Data.rename(columns=dbNames)\n#     Data.to_csv('temp/BB1_VPD.csv')\n\n# else:\nSite = 'BB'\nData = pd.read_csv(f'temp/{Site}_VPD.csv',parse_dates=['TimeStamp'],index_col='TimeStamp')\n    \nprint(Data.head())\n\nData['VPD'] = MiscFuncs.Calc_VPD(Data['TA'],Data['RH'])\n    \nfig,axes=plt.subplots(1,3,figsize=(7,4))\nData.hist(column='TA',ax=axes[0],bins=20,edgecolor='k')\naxes[0].set_xlabel(units['TA'])\n\nData.hist(column='RH',ax=axes[1],bins=20,edgecolor='k')\naxes[1].set_xlabel(units['RH'])\n\nData.hist(column='VPD',ax=axes[2],bins=20,edgecolor='k')\naxes[2].set_xlabel(units['VPD'])\n\nplt.tight_layout()\n\nData.describe().round(1)"
  },
  {
    "objectID": "about_BU.html#artificial-gaps",
    "href": "about_BU.html#artificial-gaps",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Artificial Gaps",
    "text": "Artificial Gaps"
  },
  {
    "objectID": "about_BU.html#next-steps-speculations",
    "href": "about_BU.html#next-steps-speculations",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Next Steps & Speculations",
    "text": "Next Steps & Speculations\n\nu* filtering\nFlux footprint calculations"
  },
  {
    "objectID": "about_BU.html#conclusions",
    "href": "about_BU.html#conclusions",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Conclusions",
    "text": "Conclusions\nThey offer the user more control over the structure of the model and inspection of the model derivatives provides a method for validating that the relationships mapped by a model are physically plausible."
  },
  {
    "objectID": "about_BU.html#questions",
    "href": "about_BU.html#questions",
    "title": "Neural Networks for Eddy Covariance",
    "section": "Questions",
    "text": "Questions"
  }
]