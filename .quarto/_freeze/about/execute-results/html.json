{
  "hash": "0e93dd83907fab5f0923cc02ffcb5038",
  "result": {
    "markdown": "---\ntitle: A Framework for Applying Neural Networks to Eddy Covariance Data\necho: false\nfig-dpi: 300\nformat:\n  revealjs:\n    code-fold: true\n    controls: true\n    navigation-mode: linear\n    controls-layout: bottom-right\n    controls-tutorial: true\n    slide-number: true\n    show-slide-number: all\n    pdfMaxPagesPerSlide: 1\nauthor:\n  - name: Dr. June Skeeter\n    email: june.skeeter@ubc.ca\n    url: 'https://github.com/June-Skeeter'\n    affiliations:\n      - ref: UBC\naffiliations:\n  - id: UBC\n    name: University British Columbia\n    department: Department Geography\n    address: 1984 West Mall\n    city: 'Vancouver, BC, Canada'\n    postal-code: V6T 1Z2\nkeywords:\n  - Eddy Covariance\n  - Micrometeorology\n  - Neural Networks\n  - Modelling\n---\n\n## Eddy Covariance\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nSemi-continuous, ecosystem-scale measurements of energy, water, and trace gas fluxes.\n\n* Noisy, voluminous data sets\n  * Frequent gaps\n  * Observational bias\n* Well suited for machine learning!\n\n:::\n\n::: {.column width=\"50%\"}\n\n<img src=\"images/BB1_System.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black;\">\n\n<h3>Burns Bog EC Station<br>Delta, BC</h3>\n\n:::\n\n::::\n\n\n## Neural Networks\n\n**Universal approximators**: can map any continuous function to an arbitrary degree accuracy.\n\n* With enough hidden nodes, will fit **any** pattern in a dataset\n  * Care must be taken to ensure the patterns are real\n  * Early stopping allows \n\n* Well suited for non-linear, multi-variate response functions\n  * Capable **interpolation** and *extrapolation*\n\n\n## Commonly Cited Limitations\n\n::: {.cell tbl-colwidths='[40,60]' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\nIssue                      Solutions\n-------------------------  ------------------------------------------------------------------\nOver-fitting               - Model ensembles<br>- 3-way cross validation <br>- Pruning inputs\nBlack boxes models         - Plot partial derivatives <br>- Feature importance\nComputationally expensive  - Tensorflow <br>- GPU processing\n:::\n:::\n\n\n# Objective\n\nProvide a framework for applying NN models to EC data for descriptive analysis and inferential modelling. \n \n* The [github repository](https://github.com/June-Skeeter/NN_Applications) linked to this presentation has functional examples that can be used to apply NN models.\n  * Runs in Python and Tensorflow\n    * *GPU support not required*\n\n## Example Data\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\nBurns Bog EC station\n\n* Harvested peatland undergoing active restoration\n* 8+ years of meteorological & flux (CO<sub>2</sub> and CH<sub>4</sub>) data\n\n:::\n\n::: {.column width=\"55%\"}\n\n\n<img src=\"images/BB1.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black; width: 100%\">\n\n:::\n::::\n\n\n## Training Procedures\n\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\n* Larger ensemble = more robust model\n  * N <= 10 for data exploration/pruning\n* Three way cross-validation\n  * Train/validate/test\n* Early Stopping: after **e** epochs\n  * e = 2 for pruning stage\n\n:::\n\n::: {.column width=\"30%\"}\n\n<img src=\"images/NN_Workflows.png\" alt=\"your-image-description\">\n\n\n:::\n\n::::\n\n## Pruning Inputs\n\nCalculate partial first derivative of the output with respect to each input over test data domain.\n\n* **Relative Influence (RI)** of inputs\n  * Normalized sum of squared derivatives (SSD)\n\n* Iteratively remove inputs with RI below a threshold\n  * Use set of random scalars inputs to determine threshold\n    * e.g., a float [0-1], a skewed float [0-1]<sup>.25</sup>, and a binary integer (0/1)\n\n## Before and After Pruning FCO<sub>2</sub>\n\n::: {.cell layout-ncol='1' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/ri-of-fco2-models-output-1.png){#ri-of-fco2-models width=2969 height=1465}\n:::\n:::\n\n\n## The Final Model\n\nOnce pruning is complete, re-train the final production level model, excluding the random scalars\n\n* Increase the ensemble size (e.g., N =30)\n  * Could increase early stopping criteria (e.g., e = 10)\n  * Larger e drastically increases training\n* Plot the model derivatives as a final check\n  * If derivatives look implausible \n    * Adjust inputs/parameters and try again\n\n\n## Plotting Derivatives\n    \nHelps ensure model responses are physically plausible\n\n* An **essential step** and **key advantage** of NN models\n* Raw derivatives show true feature responses\n* Normalized derivatives scaled by input variance\n  * Relative input effects on common scale\n  * What the model \"sees\"\n* 95% confidence intervals around derivatives indicate modeled confidence in relationships\n\n\n## Partial Derivatives of FCO<sub>2</sub>\n\n::: {.cell layout-ncol='1' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/derivatives-of-final-fco2-model-output-1.png){#derivatives-of-final-fco2-model width=2968 height=1469}\n:::\n:::\n\n\n## Normalized Derivatives of FCO<sub>2</sub>\n\n::: {.cell layout-ncol='1' execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/normalized-derivatives-of-final-fco2-model-output-1.png){#normalized-derivatives-of-final-fco2-model width=2968 height=1469}\n:::\n:::\n\n\n## Model Performance FCO<sub>2</sub>\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nPlot the model outputs and validation metrics calculated with the test data.\n\n::: {style=\"font-size: 80%;\"}\n\n::: {.cell layout-ncol='1' tbl-colwidths='[25,75]' execution_count=5}\n\n::: {#validation-fco2 .cell-output .cell-output-display execution_count=5}\nMetric         Score\n-------------  -----------------------------\nRMSE           0.45 $\\mu mol$ $m^{-2}s^{-1}$\nr<sup>2</sup>  0.89\n:::\n:::\n\n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-ncol='1' execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/performance-of-final-fch4-model-output-1.png){#performance-of-final-fch4-model width=1370 height=1342}\n:::\n:::\n\n\n:::\n\n::::\n\n\n## Before and After Pruning FCH<sub>4</sub>\n\n::: {.cell layout-ncol='1' execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/ri-of-fch4-models-output-1.png){#ri-of-fch4-models width=2967 height=1465}\n:::\n:::\n\n\n## Normalized Derivatives of FCH<sub>4</sub>\n\n::: {.cell layout-ncol='1' execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/derivatives-of-final-fch4-model-output-1.png){#derivatives-of-final-fch4-model width=2968 height=1469}\n:::\n:::\n\n\n## Model Performance FCH<sub>4</sub>\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nPlot the model outputs and validation metrics calculated with the test data.\n\n::: {style=\"font-size: 80%;\"}\n\n::: {.cell layout-ncol='1' tbl-colwidths='[25,75]' execution_count=9}\n\n::: {#validation-fch4 .cell-output .cell-output-display execution_count=9}\nMetric         Score\n-------------  -------------------\nRMSE           8.58 $\n               mol$ $m^{-2}s^{-1}$\nr<sup>2</sup>  0.63\n:::\n:::\n\n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-ncol='1' execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/performance-of-final-fco2-model-output-1.png){#performance-of-final-fco2-model width=1397 height=1342}\n:::\n:::\n\n\n:::\n\n::::\n\n\n## Next Steps\n\n* Custom NN architecture: Separating input layers may allow us partition fluxes.\n  * e.g., FCO<sub>2</sub> into GPP and ER\n* Flux footprints: map response to spatial heterogenity\n* Upscaling: in space and time\n* u* filtering: partial derivatives could identify u* thresholds\n* Compare to process based models (e.g., CLASSIC)\n\n# Thank You\n\nQuestions?\n\n",
    "supporting": [
      "about_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}