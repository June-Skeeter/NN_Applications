{
  "hash": "d6740b89db92f5f9f160be0b16cfe012",
  "result": {
    "markdown": "---\ntitle: A Framework for Applying Neural Networks to Eddy Covariance Data\necho: false\nfig-dpi: 300\nformat:\n  revealjs:\n    code-fold: true\n    controls: true\n    navigation-mode: linear\n    controls-layout: bottom-right\n    controls-tutorial: true\n    slide-number: true\n    show-slide-number: all\n    pdfMaxPagesPerSlide: 1\nauthor:\n  - name: Dr. June Skeeter\n    email: june.skeeter@ubc.ca\n    url: 'https://github.com/June-Skeeter'\n    affiliations:\n      - ref: UBC\naffiliations:\n  - id: UBC\n    name: University British Columbia\n    department: Department Geography\n    address: 1984 West Mall\n    city: 'Vancouver, BC, Canada'\n    postal-code: V6T 1Z2\nkeywords:\n  - Eddy Covariance\n  - Micrometeorology\n  - Neural Networks\n  - Modelling\n---\n\n## Eddy Covariance\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nEcosystem-scale fluxes energy, water, and trace gases.\n\n* Voluminous data sets\n  * Noisy & gap-prone\n* Ideally suited for machine learning!\n\n:::\n\n::: {.column width=\"50%\"}\n\n<img src=\"images/BB1_System.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black;\">\n\n<h3>Burns Bog EC Station<br>Delta, BC</h3>\n\n:::\n\n::::\n\n\n## Neural Networks\n\n**Universal approximators**: they can map any continuous function to an arbitrary degree accuracy.\n\n* With sufficient hidden nodes, they will fit **any** pattern in a dataset\n  * Care must be taken to ensure the patterns are real\n    * Have often been treated as \"black boxes\"\n\n* Well suited for non-linear, multi-variate response functions\n  * Capable *interpolation* and **extrapolation**\n\n## Commonly Cited Limitations\n\n::: {.cell tbl-colwidths='[40,60]' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\nIssue                      Solutions\n-------------------------  -------------------------------------------------------------\nOver-fitting               * Model ensembles<br> * 3-way cross validation <br> * pruning\nBlack boxes models         * Plot partial derivatives <br> * feature importance\nComputationally expensive  * Tensorflow <br> * GPU processing\n:::\n:::\n\n\n# Objective\n\nProvide a framework for applying NN models can be applied to EC data for both descriptive analysis and inferential modelling. \n \n* The [github repository](https://github.com/June-Skeeter/NN_Applications) linked to this presentation has functional examples that can be used to apply NN models.\n  * Runs in Python and Tensorflow: *GPU support not required*\n\n\n## Example Data\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\nBB1 EC station\n\n* Beakrush-Sphagnum ecosystem undergoing active restoration\n* 8+ years of CO<sub>2</sub> and CH<sub>4</sub> flux observations\n\n:::\n\n::: {.column width=\"60%\"}\n\n\n<img src=\"images/BB1.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black; width: 100%\">\n\n\n:::\n::::\n\n\n## Training Procedures\n\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\nAn iterative process:\n\n* Three way cross-validation\n  * Train & validate - random split by model \n  * Test - consistent between models\n\n* Ensemble-size\n  * Larger ensemble > more robust model\n  * N = 10 likely suitable for most applications\n\n:::\n\n::: {.column width=\"30%\"}\n\n<img src=\"images/NN_Workflows.png\" alt=\"your-image-description\">\n\n\n:::\n\n::::\n\n## How to Prune a Model\n\nCalculate partial first derivative of the output with respect to each input over test data domain.\n\n* **Relative Influence (RI)**:  Normalized Sum of squared derivatives (SSD)\n\n* Iteratively prune inputs with RI below a reference threshold\n  * Random input assess base-level performance\n\n* Train final model without random scalar\n\n## Pruning a FCO<sub>2</sub> Model\n\n::: {.cell layout-ncol='1' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/ri-of-models-output-1.png){#ri-of-models width=2968 height=1467}\n:::\n:::\n\n\n## Model Inspection\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nPlot the model outputs using the test data.\n\n\n::: {style=\"font-size: 80%;\"}\n\n::: {.cell layout-ncol='1' tbl-colwidths='[25,75]' execution_count=3}\n\n::: {#validation .cell-output .cell-output-display execution_count=3}\nMetric         Score\n-------------  -----------------------------\nRMSE           0.59 $\\mu mol$ $m^{-2}s^{-1}$\nr<sup>2</sup>  0.86\n:::\n:::\n\n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-ncol='1' execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/performance-of-final-model-output-1.png){#performance-of-final-model width=1370 height=1342}\n:::\n:::\n\n\n:::\n\n::::\n\n## Plotting Derivatives\n    \nHelp ensure mapped relationships are physically plausible\n\n* An **essential step** and **key advantage** NN models\n* Raw derivatives show true feature responses\n  * 95% confidence intervals indicate model confidence in relationships\n* Normalized derivatives scaled by input variance\n  * View relative on common scale\n\n\n## Partial Derivatives of FCO<sub>2</sub>\n\n::: {.cell layout-ncol='1' execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/derivatives-of-final-model-output-1.png){#derivatives-of-final-model width=2947 height=1469}\n:::\n:::\n\n\n## Normalized Partial Derivatives\n\n::: {.cell layout-ncol='1' execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/normalized-derivatives-of-final-model-output-1.png){#normalized-derivatives-of-final-model width=2947 height=1468}\n:::\n:::\n\n\n## Next Steps\n\n* Custom NN architecture: Separating input layers may allow us partition fluxes.\n  * FCO<sub>2</sub> into GPP and ER\n  * FCH<sub>4</sub> into methanogenesis, methanotrophy, transport\n* Flux footprint analysis: Models can help account for spatial heterogeneity within a a footprint\n  * NN could also be trained to calculate/classify footprints!\n* u* filtering: Partial derivatives of u* could give thresholds for filtering\n\n# Thank You\n\nQuestions?\n\n## Why not use a Random Forest?\n\nRF models are great! ... for classifying discrete objects\n\n* But, it's my view that applying them to continuous data is misguided\n* They are [poorly suited](https://github.com/June-Skeeter/NN_Applications) for interpolation and incapable of extrapolation\n\n",
    "supporting": [
      "about_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}