{
  "hash": "697cb8c5286c097ca017d6b6719b2c6e",
  "result": {
    "markdown": "---\ntitle: A Framework for Applying Neural Networks to Eddy Covariance Data\necho: false\nfig-dpi: 300\nformat:\n  revealjs:\n    code-fold: true\n    controls: true\n    navigation-mode: linear\n    controls-layout: bottom-right\n    controls-tutorial: true\n    slide-number: true\n    show-slide-number: all\n    pdfMaxPagesPerSlide: 1\nauthor:\n  - name: Dr. June Skeeter\n    email: june.skeeter@ubc.ca\n    url: 'https://github.com/June-Skeeter'\n    affiliations:\n      - ref: UBC\naffiliations:\n  - id: UBC\n    name: University British Columbia\n    department: Department Geography\n    address: 1984 West Mall\n    city: 'Vancouver, BC, Canada'\n    postal-code: V6T 1Z2\nkeywords:\n  - Eddy Covariance\n  - Micrometeorology\n  - Neural Networks\n  - Modelling\n---\n\n## Eddy Covariance\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nSemi-continuous, ecosystem-scale measurements of energy, water, and trace gas fluxes.\n\n* Noisy, voluminous data sets\n  * Frequent gaps\n  * Observational bias\n* Well suited for machine learning!\n\n:::\n\n::: {.column width=\"50%\"}\n\n<img src=\"images/BB1_System.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black;\">\n\n<h3>Burns Bog EC Station<br>Delta, BC</h3>\n\n:::\n\n::::\n\n\n## Neural Networks\n\n**Universal approximators**: can map any continuous function to an arbitrary degree accuracy.\n\n* Well suited for non-linear, multi-variate response functions\n  * Capable **interpolation** and *extrapolation*\n\n* With enough nodes, they will fit **any** pattern in a dataset\n  * Often treated as \"black boxes\"\n  * Care must be taken to ensure the patterns are real\n\n\n## Commonly Cited Limitations\n\n::: {.cell tbl-colwidths='[40,60]' execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=79}\nIssue                      Solutions\n-------------------------  ------------------------------------------------------------------\nOver-fitting               - Model ensembles<br>- 3-way cross validation <br>- Pruning inputs\nBlack boxes models         - Plot partial derivatives <br>- Feature importance\nComputationally expensive  - Tensorflow <br>- GPU processing\n:::\n:::\n\n\n# Objective\n\nProvide a framework for applying NN models to EC data for descriptive analysis and inferential modelling. \n \n* The [github repository](https://github.com/June-Skeeter/NN_Applications) linked to this presentation has functional examples that can be used to apply NN models.\n  * Runs in Python and Tensorflow\n    * *GPU support not required*\n\n## Example Data\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\nBurns Bog EC station\n\n* Harvested peatland undergoing active restoration\n* 8+ years of meteorological & flux (CO<sub>2</sub> and CH<sub>4</sub>) data\n\n:::\n\n::: {.column width=\"55%\"}\n\n\n<img src=\"images/BB1.jpg\" alt=\"your-image-description\" style=\"border: 2px solid  black; width: 100%\">\n\n:::\n::::\n\n\n## Training Procedures\n\n\n:::: {.columns}\n\n::: {.column width=\"70%\"}\n\nAn iterative process:\n\n* Three way cross-validation\n  * Train/validate - random split by model \n  * Test - consistent between models\n* Larger ensemble > more robust model\n  * N <= 10 suitable for exploration\n  * N >=30 will give best performance\n\n:::\n\n::: {.column width=\"30%\"}\n\n<img src=\"images/NN_Workflows.png\" alt=\"your-image-description\">\n\n\n:::\n\n::::\n\n## Pruning Inputs\n\nCalculate partial first derivative of the output with respect to each input over test data domain.\n\n* **Relative Influence (RI)** of inputs\n  * Normalized Sum of squared derivatives (SSD)\n\n* Iteratively remove inputs with RI below a threshold\n  * Use a Random scalar input to inform threshold\n\n* Train final model without random scalar\n\n## Before and After Pruning\n\n::: {.cell layout-ncol='1' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/ri-of-models-output-1.png){#ri-of-models width=2967 height=1465}\n:::\n:::\n\n\n## Model Inspection\n\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n\nPlot the model outputs and validation metrics calculated with the test data.\n\n::: {style=\"font-size: 80%;\"}\n\n::: {.cell layout-ncol='1' tbl-colwidths='[25,75]' execution_count=3}\n\n::: {#validation .cell-output .cell-output-display execution_count=81}\nMetric         Score\n-------------  -----------------------------\nRMSE           0.57 $\\mu mol$ $m^{-2}s^{-1}$\nr<sup>2</sup>  0.88\n:::\n:::\n\n\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-ncol='1' execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/performance-of-final-model-output-1.png){#performance-of-final-model width=1374 height=1348}\n:::\n:::\n\n\n:::\n\n::::\n\n## Plotting Derivatives\n    \nHelps ensure model responses are physically plausible\n\n* An **essential step** and **key advantage** of NN models\n* Raw derivatives show true feature responses\n* Normalized derivatives scaled by input variance\n  * Relative effects on common scale\n  * What the model \"sees\"\n* 95% confidence intervals around derivatives indicate modeled confidence in relationships\n\n\n## Partial Derivatives of FCO<sub>2</sub>\n\n::: {.cell layout-ncol='1' execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/derivatives-of-final-model-output-1.png){#derivatives-of-final-model width=2947 height=1468}\n:::\n:::\n\n\n## Normalized Partial Derivatives\n\n::: {.cell layout-ncol='1' execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](about_files/figure-revealjs/normalized-derivatives-of-final-model-output-1.png){#normalized-derivatives-of-final-model width=2968 height=1468}\n:::\n:::\n\n\n## Next Steps\n\n* Custom NN architecture: Separating input layers may allow us partition fluxes.\n  * FCO<sub>2</sub> into GPP and ER\n  * FCH<sub>4</sub> into methanogenesis, methanotrophy, transport\n* Flux footprints: map response to spatial heterogenity\n* Up scalling: in space and time\n* u* filtering: partial derivatives could identify u* thresholds for filtering\n\n# Thank You\n\nQuestions?\n\n## Why not use a Random Forest?\n\nRF models are great! ... for classifying discrete objects\n\n* But, it's my view that applying them to continuous data is misguided\n* They are [poorly suited](https://june-skeeter.github.io/NN_Applications/NN_for_EC.html#evaluate-and-prune-the-model) for interpolation and incapable of extrapolation\n\n",
    "supporting": [
      "about_files/figure-revealjs"
    ],
    "filters": [],
    "includes": {}
  }
}