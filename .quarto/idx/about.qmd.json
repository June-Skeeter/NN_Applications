{"title":"A Framework for Applying Neural Networks to Eddy Covariance Data","markdown":{"yaml":{"title":"A Framework for Applying Neural Networks to Eddy Covariance Data","format":{"html":{"code-fold":true}},"jupyter":"python3"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\nEC data is poorly suited for traditional statistical methods @wegman_computational_1988\n\n* Site specific approaches are often needed for EC data\n    * **But** from these *site specific* functional relationships, we hope to glean \"universal\" truths.\n\n* We need to ensure our results are reasonable given our understanding of system.\n    * And if they don't, we need to be able to see \"why\"\n  \n* As the period of record at sites extend (e.g, decades) the task only becomes more complex\n    * A sliver lining - computational statistics are ideally suited for voluminous data sets!\n\n##\tMachine Learning\n\nWe provide examples to demonstrate how NN models can be used for inferential modelling\n\ndetecting and mapping functional relationships \npattern recognition and feature detection\ndemonstrate how they can be used to map response functions,\nshow their ability to inferential modelling Gap-filling\n\n\n gap filling of EC data and for understanding the \n\nThey offer the user more control over the structure of the model and inspection of the model derivatives provides a method for validating that the relationships mapped by a model are physically plausible.  \n\n\nSite specific approaches are often needed work with EC data, but from these {site specific} functional relationships, we hope to glean {universal} truths.\n\nWe need to ensure that the results conform to our values reasonably expected {given our understanding of system/the framework of our conceptual model}.  And if they don't, we need to be able to see \"why\" in order to ensure ...\n\n\n# Calculating and Visualizing VPD\n\nThe Vapor Pressure Deficit (VPD) decreases exponentially as a function of air temperature (Ta) and linearly as a function of relative humidity (RH).  We can calculate VPD (kPa) from Ta in ($\\circ$ C) and RH (%) as follows:\n\n$$ ea_H = 0.61365*np.exp((17.502*Ta)/(240.97+Ta))$$\n$$e_H = RH*ea_H/100$$\n$$VPD = (ea_H - e_H)*10$$\n\n```{python}\n#| label: Estimating VPD\n#| fig-cap: \"This plot shows the relationship between VPD, TA, and RH over a range of possible values\"\n#| layout-ncol: 1\n#| warning: False\n\nimport numpy as np\nfrom Scripts import MiscFuncs,PlotHelpers\nimport matplotlib.pyplot as plt\n\nunits = {\n    'Ta':'$T_a^\\circ$C',\n    'RH':'RH %',\n    'VPD':'VPD hPa'\n    }\n\nlabels = {\n    'Ta':'Air Temperature',\n    'RH':'Relative Humidity',\n    'VPD':'Vapor Pressure Deficit'\n    }\n\nrange_TA_RH,grid_TA,grid_RH,grid_VPD = MiscFuncs.Create_Grid(\n    np.linspace(-50,50),# Define a TA range (in C)\n    np.linspace(0,100), # Possible RH values\n    MiscFuncs.Calc_VPD # Return Vapor Pressure Defecit\n    )\n    \nbins = np.arange(5,grid_VPD.max(),15)\ncmap = 'bwr'\nnorm = [0,grid_VPD.max()]\n\nfig,ax=plt.subplots(1,figsize=(5,5))\nPlotHelpers.Contour_Plot(fig,ax,grid_TA,grid_RH,grid_VPD,cmap=cmap,norm=norm,unit = units['VPD'],bins=bins)\nax.set_xlabel('Air Temperature $^\\circ$C')\nax.set_ylabel('Relative Humidity %')\nax.set_title('Vapor Pressure Deficit (VPD)')\nplt.tight_layout()\n\n```\n\n## Partial Derivatives\n\n```{python}\n#| label: Derivatives of VPD\n#| fig-cap: \"This plot shows the partial first derivatives of VPD\"\n#| layout-ncol: 1\n#| warning: False\nimport pandas as pd\nimport tensorflow as tf\n\n# Use tensorfolow to calculate the first partial derivative of the function\nX_tensor = tf.convert_to_tensor(range_TA_RH.T)\nwith tf.GradientTape(persistent=True) as tape:\n    tape.watch(X_tensor)\n    VPD_est = MiscFuncs.Calc_VPD(X_tensor) \n\n# Get gradients of VPD_est with respect to X_tensor\nDeriv = tape.gradient(VPD_est,X_tensor).numpy()\nDerivatives = pd.DataFrame(\n    data={\n    'TA':range_TA_RH.T[:,0],\n    'RH':range_TA_RH.T[:,1],\n    'dVPD/dTA':Deriv[:,0],\n    'dVPD/dRH':Deriv[:,1]\n    }\n)\n\n\nfig,axes=plt.subplots(2,2,figsize=(8,8),sharey='row')\n\ndf,x,y = MiscFuncs.byInterval(Derivatives,'TA','dVPD/dTA',bins=100)\nax = PlotHelpers.CI_Plot(axes[0,0],df,y)\nax.set_title('Partial First Derivative\\nVPD with respect to Ta')\n\ndf,x,y = MiscFuncs.byInterval(Derivatives,'RH','dVPD/dRH',bins=100)\nax = PlotHelpers.CI_Plot(axes[0,1],df,y)\nax.set_title('Partial First Derivative\\nVPD with respect to RH')\n\ngrid_dVPD_dTA = Deriv[:,0].T.reshape(grid_TA.shape)\ngrid_dVPD_dRH = Deriv[:,1].T.reshape(grid_RH.shape)\n\nd_bins = np.arange(\n    np.floor(Deriv).min(),np.ceil(Deriv).max(),.5\n    )\nd_norm = [\n    Deriv.min(), Deriv.max()\n    ]\n    \nax=axes[1,0]\nPlotHelpers.Contour_Plot(fig,ax,grid_TA,grid_RH,grid_dVPD_dTA,cmap = cmap,norm=d_norm,bins=d_bins)\nax.set_title('dVPD dTa')\n\nax=axes[1,1]\nPlotHelpers.Contour_Plot(fig,ax,grid_TA,grid_RH,grid_dVPD_dRH,cmap = cmap,norm=d_norm,bins=d_bins)\nax.set_title('dVPD dRH')\n\nplt.tight_layout()\n```\n\n\n# Example Data\n\nBB1 Flux tower was established in 2015.\n\n```{python}\nfrom Scripts import ReadDB\n\ndbNames = {\n    'TA_1_1_1':'Ta',\n    'RH_1_1_1':'RH'\n}\n\nData = ReadDB.get_Traces('BB',['TA_1_1_1','RH_1_1_1'])\nData = Data.dropna(axis=0)\n\nData = Data.rename(columns=dbNames)\n\nData['VPD'] = MiscFuncs.Calc_VPD(Data['Ta'],Data['RH'])\n\nfig,axes=plt.subplots(1,3,figsize=(7,4))\nData.hist(column='Ta',ax=axes[0],bins=20,edgecolor='k')\naxes[0].set_xlabel(units['Ta'])\n\nData.hist(column='RH',ax=axes[1],bins=20,edgecolor='k')\naxes[1].set_xlabel(units['RH'])\n\nData.hist(column='VPD',ax=axes[2],bins=20,edgecolor='k')\naxes[2].set_xlabel(units['VPD'])\n\nplt.tight_layout()\n\nplt.show()\n\nData.describe().round(1)\n```\n\n\n# Artificial Gaps\n\nBB1 Flux tower was established in 2015.\n\n\n```{python}\n#| label: fig-format\n#| fig-cap: \"Format the training data\" \n#| layout-ncol: 1\n#| warning: False\n\nX_vars = ['Ta', 'RH']\nY_var = 'VPD'\n\nX_full = Data[X_vars].values\nY_full = Data[Y_var].values\nprint('Full Training Samples: ',Y_full.shape)\n\nMask = np.array([2.5,7.5])\n# Masked dataset for training\nx_mask = Data.loc[(\n    (Data[Y_var]<Mask.min())|(Data[Y_var]>Mask.max())\n    ),X_vars].values\ny_mask = Data.loc[(\n    (Data[Y_var]<Mask.min())|(Data[Y_var]>Mask.max())\n    ),Y_var].values\nprint('Masked Samples: ',y_mask.shape)\n\n# Missing values for assessing performance\nx_missing = Data.loc[Data[Y_var].isin(y_mask)==False,X_vars].values\ny_missing = Data.loc[Data[Y_var].isin(y_mask)==False,Y_var].values\nprint('Missing Samples: ',y_missing.shape)\n```"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"about.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title":"A Framework for Applying Neural Networks to Eddy Covariance Data","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}}}}