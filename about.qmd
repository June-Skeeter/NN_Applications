---
title: "A Framework for Applying Neural Networks to Eddy Covariance Data"
format:
  html:
    code-fold: true
jupyter: python3
---

# Introduction 

EC data is poorly suited for traditional statistical methods @wegman_computational_1988

* Site specific approaches are often needed for EC data
    * **But** from these *site specific* functional relationships, we hope to glean "universal" truths.

* We need to ensure our results are reasonable given our understanding of system.
    * And if they don't, we need to be able to see "why"
  
* As the period of record at flux sites extend (e.g, decades) the task only becomes more complex
    * A sliver lining - computational statistics are ideally suited for voluminous data sets!

##	Machine Learning


Site specific approaches are often needed work with EC data, but from these {site specific} functional relationships, we hope to glean {universal} truths.

We need to ensure that the results conform to our values reasonably expected {given our understanding of system/the framework of our conceptual model}.  And if they don't, we need to be able to see "why" in order to ensure ...

## Neural Network Models

They offer the user more control over the structure of the model and inspection of the model derivatives provides a method for validating that the relationships mapped by a model are physically plausible. 

# Objectives

We provide examples to demonstrate how NN models can be used for descriptive analysis and inferential modelling.

* Detecting and mapping functional relationships 
* Pruning models
* Gap filling, upscaling, and projection
 



# Calculating and Visualizing VPD

The Vapor Pressure Deficit (VPD) decreases exponentially as a function of air temperature (Ta) and linearly as a function of relative humidity (RH).  We can calculate VPD (kPa) from Ta in ($\circ$ C) and RH (%) as follows:

$$ ea_H = 0.61365*np.exp((17.502*Ta)/(240.97+Ta))$$
$$e_H = RH*ea_H/100$$
$$VPD = (ea_H - e_H)*10$$

```{python}
#| label: Estimating VPD
#| fig-cap: "This plot shows the relationship between VPD, TA, and RH over a range of possible values"
#| layout-ncol: 1
#| warning: False

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt

from Scripts import MiscFuncs,PlotHelpers

units = {
    'Ta':'$T_a^\circ$C',
    'RH':'RH %',
    'VPD':'VPD hPa'
    }

labels = {
    'Ta':'Air Temperature',
    'RH':'Relative Humidity',
    'VPD':'Vapor Pressure Deficit'
    }

range_TA_RH,grid_TA,grid_RH,grid_VPD = MiscFuncs.Create_Grid(
    np.linspace(-50,50),# Define a TA range (in C)
    np.linspace(0,100), # Possible RH values
    MiscFuncs.Calc_VPD # Return Vapor Pressure Defecit
    )
    
bins = np.arange(-10,grid_VPD.max(),15)
cmap = 'PuRd'
norm = [0,grid_VPD.max()]

fig,ax=plt.subplots(1,figsize=(5,5))
PlotHelpers.Contour_Plot(fig,ax,grid_TA,grid_RH,grid_VPD,cmap=cmap,norm=norm,unit = units['VPD'],bins=bins)
ax.set_xlabel('Air Temperature $^\circ$C')
ax.set_ylabel('Relative Humidity %')
ax.set_title('Vapor Pressure Deficit (VPD)')
plt.tight_layout()

# Use tensorfolow to calculate the first partial derivative of the function
X_tensor = tf.convert_to_tensor(range_TA_RH.T)
with tf.GradientTape(persistent=True) as tape:
    tape.watch(X_tensor)
    VPD_est = MiscFuncs.Calc_VPD(X_tensor) 
# Get gradients of VPD_est with respect to X_tensor
Deriv = tape.gradient(VPD_est,X_tensor).numpy()


Derivatives = pd.DataFrame(
    data={
    'TA':range_TA_RH.T[:,0],
    'RH':range_TA_RH.T[:,1],
    'dVPD/dTA':Deriv[:,0],
    'dVPD/dRH':Deriv[:,1]
    }
)

fig,axes=plt.subplots(2,2,figsize=(8,8),sharey='row')

grid_dVPD_dTA = Deriv[:,0].T.reshape(grid_TA.shape)
grid_dVPD_dRH = Deriv[:,1].T.reshape(grid_RH.shape)

d_bins = np.arange(
    np.floor(Deriv).min(),np.ceil(Deriv).max(),.5
    )
d_cmap = 'bwr'
d_norm = [
    Deriv.min(),0, Deriv.max()
    ]
    
ax,_ = PlotHelpers.Contour_Plot(fig,axes[0,0],grid_TA,grid_RH,grid_dVPD_dTA,cmap = d_cmap,norm=d_norm,bins=d_bins)
ax.set_title('dVPD dTa')

ax,_ = PlotHelpers.Contour_Plot(fig,axes[0,1],grid_TA,grid_RH,grid_dVPD_dRH,cmap = d_cmap,norm=d_norm,bins=d_bins)
ax.set_title('dVPD dRH')


df,x,y = MiscFuncs.byInterval(Derivatives,'TA','dVPD/dTA',bins=100)
ax = PlotHelpers.CI_Plot(axes[1,0],df,y)
# ax.set_title('Partial First Derivative\nVPD with respect to Ta')

df,x,y = MiscFuncs.byInterval(Derivatives,'RH','dVPD/dRH',bins=100)
ax = PlotHelpers.CI_Plot(axes[1,1],df,y)
# ax.set_title('Partial First Derivative\nVPD with respect to RH')


plt.tight_layout()

```

## Partial Derivatives

```{python}
#| label: Derivatives of VPD
#| fig-cap: "This plot shows the partial first derivatives of VPD"
#| layout-ncol: 1
#| warning: False
grid_VPD.min()


```


# Example Data

BB1 Flux tower was established in 2015.

```{python}
from Scripts import ReadDB

dbNames = {
    'TA_1_1_1':'Ta',
    'RH_1_1_1':'RH'
}

read_new = True
if read_new == False:
    Data = ReadDB.get_Traces('BB',['TA_1_1_1','RH_1_1_1'],Dir='/mnt/c/Users/User/PostDoc_Work/database/')
    print(Data)
    Data = Data.dropna(axis=0)
    Data = Data.rename(columns=dbNames)
    Data.to_csv('temp/BB1_VPD.csv')

else:
    Data = pd.read_csv('temp/BB1_VPD.csv',parse_dates=['TimeStamp'],index_col='TimeStamp')
    
print(Data.head())

Data['VPD'] = MiscFuncs.Calc_VPD(Data['Ta'],Data['RH'])
    
fig,axes=plt.subplots(1,3,figsize=(7,4))
Data.hist(column='Ta',ax=axes[0],bins=20,edgecolor='k')
axes[0].set_xlabel(units['Ta'])

Data.hist(column='RH',ax=axes[1],bins=20,edgecolor='k')
axes[1].set_xlabel(units['RH'])

Data.hist(column='VPD',ax=axes[2],bins=20,edgecolor='k')
axes[2].set_xlabel(units['VPD'])

plt.tight_layout()

Data.describe().round(1)
```


# Artificial Gaps


```{python}
#| label: fig-format
#| fig-cap: "Format the training data" 
#| layout-ncol: 1
#| warning: False

X_vars = ['Ta', 'RH']
Y_var = 'VPD'

# X_full = Data[X_vars].values
# Y_full = Data[Y_var].values
# print('Full Training Samples: ',Y_full.shape)

# Mask = np.array([-1,1])
# # Masked dataset for training
# x_mask = Data.loc[(
#     (Data[Y_var]<Mask.min())|(Data[Y_var]>Mask.max())
#     ),X_vars].values
# y_mask = Data.loc[(
#     (Data[Y_var]<Mask.min())|(Data[Y_var]>Mask.max())
#     ),Y_var].values
# print('Masked Samples: ',y_mask.shape)

# # Missing values for assessing performance
# x_missing = Data.loc[Data[Y_var].isin(y_mask)==False,X_vars].values
# y_missing = Data.loc[Data[Y_var].isin(y_mask)==False,Y_var].values
# print('Missing Samples: ',y_missing.shape)

# Make some artificial gap scenarios

# Scenarios = {
#     "Random Drop Out":{}
#     "Missing Middle":{}
#     "Clipped Wings":{}
# }

Mask = np.array([[-1,1],[2,3]])
Masked,Dropped = MiscFuncs.makeGap(Data,Y_var,Mask)

print(Masked.shape,Dropped.shape)


# print(Mask.ndim)
for mask in Mask:
    print(mask)
```

